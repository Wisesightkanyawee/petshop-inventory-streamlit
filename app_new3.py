# app.py
# Smart Reorder Tool ‚Äî robust for (Sales: SKU, Quantity, Net sales, Cost of goods, Date)
# and (Inventory: SKU, In stock [I-animal], Cost)

import streamlit as st
import pandas as pd
import numpy as np
import altair as alt

# =============== Page ===============
st.set_page_config(page_title="Smart Reorder Tool", layout="wide")
st.title("üßÆ Smart Reorder Tool")

# keep run state
if "ran" not in st.session_state:
    st.session_state["ran"] = False

# =============== UI ===============
left, right = st.columns([1, 1])

with left:
    uploaded_sales = st.file_uploader('üì§ Upload "Sales by item" file (.CSV)', type=["csv"])
    uploaded_stock = st.file_uploader('üì§ Upload "Inventory" file (.CSV)', type=["csv"])
    stock_days   = st.number_input("üì¶ Stock Coverage Target (Day)", value=45, min_value=1)
    reorder_days = st.number_input("üîÅ ‡∏™‡∏±‡πà‡∏á‡∏Ç‡∏≠‡∏á‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÉ‡∏ô‡∏≠‡∏µ‡∏Å‡∏Å‡∏µ‡πà‡∏ß‡∏±‡∏ô", value=7, min_value=1)
    st.caption("Inventory columns expected: **SKU, In stock [I-animal], Cost**")

with right:
    st.markdown("### ‚ÑπÔ∏è RU Score (Reorder Urgency)")
    st.markdown(
        "- ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ó‡∏µ‡πà‡∏ö‡∏≠‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πà‡∏á‡∏î‡πà‡∏ß‡∏ô‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏±‡πà‡∏á‡∏ã‡∏∑‡πâ‡∏≠ ‡∏´‡∏≤‡∏Å‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏´‡∏°‡∏î‡∏™‡∏ï‡πá‡∏≠‡∏Å\n"
        "- ‡∏¢‡∏¥‡πà‡∏á‡∏™‡∏π‡∏á ‚Üí ‡πÄ‡∏™‡∏µ‡∏¢‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡∏ó‡∏≥‡∏Å‡∏≥‡πÑ‡∏£‡∏ï‡πà‡∏≠‡∏ß‡∏±‡∏ô‡∏°‡∏≤‡∏Å ‡∏Ñ‡∏ß‡∏£‡πÄ‡∏ï‡∏¥‡∏°‡πÄ‡∏£‡πá‡∏ß"
    )
    st.caption("Sales columns expected: **Date, SKU, Item(optional), Quantity, Net sales, Cost of goods, Category(optional), Receipt number(optional), Customer name(optional), Customer contacts(optional)**")

st.markdown("### ")
run_center = st.columns([2, 1, 2])[1]
with run_center:
    if st.button("‚ñ∂Ô∏è Run Analysis", use_container_width=True):
        st.session_state["ran"] = True

# =============== Helpers ===============
def norm_sku(series: pd.Series) -> pd.Series:
    """Normalize SKU to a consistent string (strip, remove .0, force upper-case)."""
    s = series.astype(str)
    s = (
        s.str.replace("\u00A0", " ", regex=False)   # NBSP
         .str.replace("\u200b", "", regex=False)    # zero-width
         .str.strip()
         .str.replace(r"\.0+$", "", regex=True)
         .str.upper()
    )
    return s

def num_clean(series, fill=0.0):
    """‡πÅ‡∏õ‡∏•‡∏á‡∏™‡∏ï‡∏£‡∏¥‡∏á‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏ô‡∏ó‡∏≤‡∏ô (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Ñ‡∏≠‡∏°‡∏°‡πà‡∏≤, ‡∏ß‡∏á‡πÄ‡∏•‡πá‡∏ö‡∏ö‡∏±‡∏ç‡∏ä‡∏µ, unicode minus, scientific notation)"""
    s = pd.Series(series).astype(str)
    s = (
        s.str.replace("\u00A0", " ", regex=False)
         .str.replace("\u200b", "", regex=False)
         .str.replace(",", "", regex=False)
         .str.replace("‚àí", "-", regex=False)
         .str.replace(r"\((.*)\)", r"-\1", regex=True)
         .str.strip()
    )
    s = s.str.extract(r"([+-]?(?:\d+\.?\d*|\.\d+)(?:[eE][+-]?\d+)?)", expand=False)
    return pd.to_numeric(s, errors="coerce").fillna(fill)

def try_load_master():
    """Optional: Master SKU with Category. Safe to skip."""
    try:
        m = pd.read_csv("Master_SKU_Petshop.csv")
        m.columns = m.columns.str.strip()
        if "SKU" in m.columns:
            m["SKU"] = norm_sku(m["SKU"])
        return m
    except Exception:
        return None

def clean_columns(df: pd.DataFrame) -> pd.DataFrame:
    """‡∏•‡πâ‡∏≤‡∏á‡∏≠‡∏±‡∏Å‡∏Ç‡∏£‡∏∞‡πÅ‡∏õ‡∏•‡∏Å ‡πÜ ‡πÉ‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå ‡πÄ‡∏ä‡πà‡∏ô zero-width, BOM, NBSP"""
    df.columns = (
        df.columns.astype(str)
        .str.replace(r"[\u200B\uFEFF\u00A0]", "", regex=True)  # zero-width, BOM, NBSP
        .str.strip()
    )
    return df

def make_timegrain(df: pd.DataFrame, freq_key: str) -> pd.DataFrame:
    """Add a time grain column based on freq_key in {'Daily','Weekly','Monthly'}."""
    df = df.copy()
    if freq_key == "Daily":
        df["Timegrain"] = df["Date"].dt.to_period("D").dt.to_timestamp()
    elif freq_key == "Weekly":
        # ISO week start Monday; to_timestamp gives period start
        df["Timegrain"] = df["Date"].dt.to_period("W-MON").dt.to_timestamp()
    elif freq_key == "Monthly":
        df["Timegrain"] = df["Date"].dt.to_period("M").dt.to_timestamp()
    else:
        df["Timegrain"] = df["Date"].dt.to_period("D").dt.to_timestamp()
    return df

# <<< ‡∏ß‡∏≤‡∏á‡πÑ‡∏ß‡πâ‡πÉ‡∏Å‡∏•‡πâ ‡πÜ helpers ‡∏≠‡∏∑‡πà‡∏ô ‡πÜ >>>
def fmt_commas(df: pd.DataFrame, int_cols=(), float_cols=()):
    """Return a Styler with thousands separators."""
    fmt_map = {c: "{:,.0f}" for c in int_cols}
    fmt_map.update({c: "{:,.2f}" for c in float_cols})
    return df.style.format(fmt_map)

# ‚úÖ NEW: Styler for diverging percent tables (e.g., Change_%)
def style_diverging_percent(df: pd.DataFrame):
    """Style percent tables with a red-yellow-green gradient centered at 0.

    ‡∏°‡∏µ fallback ‡∏Å‡∏£‡∏ì‡∏µ deploy ‡πÅ‡∏•‡πâ‡∏ß‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á matplotlib (pandas Styler.background_gradient ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ matplotlib)
    ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ matplotlib ‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏™‡∏µ‡∏î‡πâ‡∏ß‡∏¢‡∏ï‡∏ô‡πÄ‡∏≠‡∏á (inline CSS) ‡πÅ‡∏ó‡∏ô
    """
    arr = df.replace([np.inf, -np.inf], np.nan).to_numpy(dtype=float)
    absmax = np.nanmax(np.abs(arr)) if arr.size else None
    if absmax and absmax > 0:
        vmin, vmax = -absmax, absmax
    else:
        vmin = vmax = None
    try:
        import matplotlib  # noqa: F401
        return (
            df.style
              .format("{:+,.2f}%")
              .background_gradient(cmap="RdYlGn", vmin=vmin, vmax=vmax, axis=None)
        )
    except Exception:
        # Manual fallback: map value -> color (red -> yellow -> green)
        def _color(val):
            if pd.isna(val) or absmax in (None, 0):
                return ""  # no style
            # normalize to [-1,1]
            norm = max(-1, min(1, val / absmax))
            # interpolate: negative -> red (rgb(220,60,50)), zero -> yellow (255, 220, 60), positive -> green (60,160,60)
            if norm >= 0:
                # yellow -> green
                r1,g1,b1 = 255,220,60
                r2,g2,b2 = 60,160,60
                t = norm
            else:
                # red -> yellow
                r1,g1,b1 = 220,60,50
                r2,g2,b2 = 255,220,60
                t = norm + 1  # map [-1,0] -> [0,1]
            r = int(r1 + (r2 - r1)*t)
            g = int(g1 + (g2 - g1)*t)
            b = int(b1 + (b2 - b1)*t)
            return f"background-color: rgb({r},{g},{b});"

        styled = df.copy()
        styler = styled.style.format("{:+,.2f}%").applymap(_color)
        return styler

# ‚úÖ NEW: ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á MoM
def build_mom_table(df, group_col, value_col):
    agg = (
        df.groupby([df["Date"].dt.to_period("M"), group_col])[value_col]
          .sum()
          .reset_index()
    )
    agg.rename(columns={value_col: "Value"}, inplace=True)
    agg["Date"] = agg["Date"].astype(str)
    agg["Change_%"] = agg.groupby(group_col)["Value"].pct_change() * 100
    return agg


# =============== Main ===============
if st.session_state.get("ran") and uploaded_sales and uploaded_stock:
    try:
        # ----- Load CSVs -----
        sales = clean_columns(pd.read_csv(uploaded_sales))
        stock = clean_columns(pd.read_csv(uploaded_stock))
        sales.columns = sales.columns.str.strip()
        stock.columns = stock.columns.str.strip()

        # ----- Harmonize SALES columns -----
        if "Net sales" not in sales.columns and "Gross sales" in sales.columns:
            sales = sales.rename(columns={"Gross sales": "Net sales"})
        if "Quantity" not in sales.columns and ("Items sold" in sales.columns or "Items refunded" in sales.columns):
            q = num_clean(sales.get("Items sold", 0))
            r = num_clean(sales.get("Items refunded", 0))
            sales["Quantity"] = q - r

        # Validate required columns (Sales)
        req_sales = {"SKU", "Quantity", "Net sales", "Cost of goods", "Date"}
        missing_sales = req_sales - set(sales.columns)
        if missing_sales:
            st.error("‚ùå Sales file missing columns: " + ", ".join(sorted(missing_sales)))
            st.stop()

        # ----- Harmonize INVENTORY columns -----
        req_stock = {"SKU", "In stock [I-animal]", "Cost"}
        missing_stock = req_stock - set(stock.columns)
        if missing_stock:
            st.error("‚ùå Inventory file missing columns: " + ", ".join(sorted(missing_stock)))
            st.stop()

        # ----- Normalize keys/types -----
        sales["SKU"] = norm_sku(sales["SKU"])
        stock["SKU"] = norm_sku(stock["SKU"])
        stock = stock.rename(columns={"In stock [I-animal]": "‡∏Ñ‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠", "Cost": "‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢/‡∏ä‡∏¥‡πâ‡∏ô"})
        stock["‡∏Ñ‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠"] = num_clean(stock["‡∏Ñ‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠"], 0)
        stock["‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢/‡∏ä‡∏¥‡πâ‡∏ô"] = num_clean(stock["‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢/‡∏ä‡∏¥‡πâ‡∏ô"], 0)

        # ----- Date filter -----
        sales["Date"] = pd.to_datetime(sales["Date"], errors="coerce")
        sales = sales.dropna(subset=["Date"])
        if sales.empty:
            st.error("‚ùå Sales file has no valid dates.")
            st.stop()

        min_day = sales["Date"].min().date()
        max_day = sales["Date"].max().date()

        st.subheader("üìÖ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå")
        c1, c2 = st.columns(2)
        with c1:
            start_day = st.date_input("‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà", value=min_day, min_value=min_day, max_value=max_day)
        with c2:
            end_day   = st.date_input("‡∏ñ‡∏∂‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà", value=max_day, min_value=min_day, max_value=max_day)
        if start_day > end_day:
            st.error("‚ùå ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏≠‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î")
            st.stop()

        # restrict range
        mask_range = (sales["Date"].dt.date >= start_day) & (sales["Date"].dt.date <= end_day)
        sales = sales.loc[mask_range].copy()
        days_of_sales = (pd.to_datetime(end_day) - pd.to_datetime(start_day)).days + 1

        # --- Parse numbers ---
        sales["Net sales"]     = num_clean(sales["Net sales"], 0)
        sales["Cost of goods"] = num_clean(sales["Cost of goods"], 0)
        sales["Quantity"]      = pd.to_numeric(sales["Quantity"], errors="coerce").fillna(0.0)
        sales["Gross profit"]  = sales["Net sales"] - sales["Cost of goods"]

        # category fallback
        if "Category" not in sales.columns:
            sales["Category"] = np.nan
        sales["Category_disp"] = sales["Category"].fillna("Uncategorized").astype(str)

        # ====== Create Brand & Cate_and_band ======

        def extract_brand(item: str) -> str:
            if not isinstance(item, str):
                return ''
            text = item.strip()
            if not text:
                return ''
            tokens = text.split()
            lt = [t.lower().strip('.,') for t in tokens]

            def join(n: int):
                return ' '.join(tokens[:n])

            # --- rules ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ---
            if len(lt) >= 4 and lt[0]=='solid' and lt[1]=='gold' and lt[2]=='indigo' and lt[3]=='moon':
                return 'solid gold indigo moon'
            if len(lt) >= 4 and lt[0]=='taste' and lt[1]=='of' and lt[2]=='the' and lt[3]=='wild':
                return 'taste of the wild'
            if lt[0]=='odour' and len(lt)>=2 and lt[1]=='lock':
                return 'odour lock multi-cat'
            if lt[0] in {'22','22pet'}:
                return '22pet'
            if lt[0] in {'boqifactory','boqi'}:
                return 'boqifactory'
            if len(lt)>=1 and (lt[0].replace('-', '') in {'meo','me0'}) or lt[0] in {'me-o','me-o,'}:
                return 'me-o'
            if lt[0]=='dog' and len(lt)>=3 and lt[1] in {'n','n,'} and lt[2]=='joy':
                return 'dog n joy'
            if lt[0]=='cat':
                if len(lt)>=3 and lt[1] in {'n','n,'} and lt[2]=='joy':
                    return 'cat n joy'
                if len(lt)>=2 and lt[1]=='taste':
                    return 'cat taste'
                if len(lt)>=2 and lt[1] in {'it','me'}:
                    return join(2)
                return tokens[0]
            if lt[0]=='bite':
                if len(lt)>=3 and lt[1]=='of':
                    if lt[2]=='wild':
                        return 'bite of wild'
                    if lt[2]=='the' and len(lt)>=4 and lt[3]=='wild':
                        return 'bite of the wild'
                return tokens[0]
            if lt[0]=='cheer' and len(lt)>=2 and lt[1]=='share':
                return 'cheer share'
            if lt[0]=='kat':
                if len(lt)>=2 and lt[1] in {'club','to'}:
                    return join(2)
                return tokens[0]
            if tokens[0].lower().rstrip('.') == 'mr':
                if len(lt)>=2 and lt[1]=='vet':
                    return 'mr vet'
                return 'mr'
            if lt[0]=='dream' and len(lt)>=2 and lt[1]=='litty':
                return 'dream litty'
            if lt[0]=='vif' and len(lt)>=2 and lt[1]=='clair':
                return 'vif clair'
            if lt[0]=='kitty':
                if len(lt)>=2 and lt[1] in {'licks','treats'}:
                    return 'kitty ' + tokens[1].lower()
                return 'kitty'
            if lt[0]=='ocean' and len(lt)>=2 and lt[1]=='star':
                return 'ocean star'
            if lt[0]=='catit' and len(lt)>=2 and lt[1]=='creamy':
                return 'catit creamy'
            if lt[0]=='dox' and len(lt)>=2 and lt[1]=='club':
                return 'dox club'
            if lt[0]=='lucky' and len(lt)>=2 and lt[1]=='dog':
                return 'lucky dog'
            if lt[0]=='bok' and len(lt)>=2 and lt[1] in {'bok','dok'}:
                return join(2)
            if lt[0]=='am' and len(lt)>=2 and lt[1]=='goat':
                return 'am goat'
            if lt[0]=='bully' and len(lt)>=2 and lt[1]=='stick':
                return 'bully stick'
            if lt[0]=='bux' and len(lt)>=2 and lt[1]=='away':
                return 'bux away'
            if lt[0]=='cotton' and len(lt)>=2 and lt[1]=='bud':
                return 'cotton bud'
            if lt[0]=='daili' and len(lt)>=2 and lt[1]=='pet':
                return 'daili pet'
            if lt[0]=='dental' and len(lt)>=2 and lt[1]=='bone':
                return 'dental bone'
            if lt[0]=='dogster' and len(lt)>=3 and lt[1]=='play' and lt[2]=='mix':
                return 'dogster play mix'
            if lt[0]=='goat' and len(lt)>=2 and lt[1]=='milk':
                return 'goat milk'
            if lt[0]=='kelly' and len(lt)>=2 and ("co" in lt[1]):
                return "kelly co's"
            if lt[0]=='lola' and len(lt)>=3 and lt[1]=='healthy' and lt[2]=='growth':
                return 'lola healthy growth'
            if lt[0]=='love':
                if len(lt)>=2 and lt[1] in {'me','cubes'}:
                    return 'love ' + tokens[1].lower()
                return 'love'
            if lt[0]=='loveme':
                return 'loveme'
            if lt[0]=='nano' and len(lt)>=2 and lt[1]=='care':
                return 'nano care'
            if lt[0]=='optimum' and len(lt)>=2 and lt[1]=='spirulina':
                return 'optimum spirulina'
            if lt[0]=='ostech' and len(lt)>=2 and lt[1]=='ultra':
                return 'ostech ultra'
            if lt[0].startswith("p'") and len(lt)>=2 and lt[1]=='sak':
                return "p' sak"
            if lt[0]=='ped' and len(lt)>=3 and lt[1]=='denta' and lt[2]=='stix':
                return 'ped denta stix'
            if lt[0]=='paws' and len(lt)>=2 and lt[1]=='feliz':
                return 'paws feliz'
            if lt[0]=='pet' and len(lt)>=2 and lt[1] in {'ranger','trainingpad'}:
                return 'pet ' + tokens[1]
            if lt[0]=='revo' and len(lt)>=2 and lt[1]=='plus':
                return 'revo plus'
            if lt[0]=='royal':
                if len(lt)>=2 and lt[1]=='topping':
                    return 'royal topping'
                if len(lt)>=3 and lt[1]=='herbal' and lt[2]=='spray':
                    return 'royal herbal spray'
                return 'royal'
            return tokens[0]

        def refine_brand(row):
            """Refine brand with case-insensitive logic and output all-lowercase.

            - Online selling platform names -> lineman / grab / tiktok
            - CAT Snack + me-o: split into me-o treat / me-o ‡πÅ‡∏°‡∏ß‡πÄ‡∏•‡∏µ‡∏¢
            Fallback: lowercase brand.
            """
            b = str(row.get('Brand', '')).strip()
            b_lower = b.lower()
            cat = str(row.get('Category', '')).strip()
            cat_upper = cat.upper()
            item = str(row.get('Item', '')).lower()

            # Online selling normalization (strip trailing codes already handled upstream by using item text)
            if cat.strip().lower() == 'online selling':
                if 'lineman' in item or item.startswith('line'):
                    return 'lineman'
                if item.startswith('grab'):
                    return 'grab'
                if 'tiktok' in item:
                    return 'tiktok'
                return b_lower

            # CAT Snack specializations for me-o
            if cat_upper == 'CAT SNACK' and b_lower in {'me-o', 'meo', 'me0'}:
                txt_low = item
                if 'treat' in txt_low:
                    return 'me-o treat'
                if '‡πÅ‡∏°‡∏ß‡πÄ‡∏•‡∏µ‡∏¢' in txt_low:
                    return 'me-o ‡πÅ‡∏°‡∏ß‡πÄ‡∏•‡∏µ‡∏¢'
                return 'me-o'

            return b_lower

        # apply
        if "Item" in sales.columns:
            # 1) extract base brand (case-insensitive rules use lower tokens) -> may return mixed case
            sales["Brand"] = sales["Item"].apply(extract_brand)
            # 2) refine & force lowercase outputs
            sales["Brand"] = sales.apply(refine_brand, axis=1)
            # 3) final brand all-lowercase (double safety)
            sales["Brand"] = sales["Brand"].str.lower()
            # 4) build Cate_and_band with lowercase brand
            sales["Cate_and_band"] = (
                sales["Category_disp"].astype(str).str.strip() + " [" + sales["Brand"].astype(str) + "]"
            )
            # 5) Ensure everything inside brackets is lowercase (already) and remove accidental double spaces
            sales["Cate_and_band"] = sales["Cate_and_band"].str.replace(r"\s+", " ", regex=True)
        else:
            sales["Cate_and_band"] = sales["Category_disp"].astype(str).str.lower()


        # KPI after filter
        cdbg1, cdbg2, cdbg3 = st.columns(3)
        cdbg1.metric("‚úÖ ‡∏£‡∏ß‡∏° Quantity (‡∏ä‡∏¥‡πâ‡∏ô)", f"{float(sales['Quantity'].sum()):,.0f}")
        cdbg2.metric("üí∞ ‡∏£‡∏ß‡∏°‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢ (‡∏ö‡∏≤‡∏ó)", f"{float(sales['Net sales'].sum()):,.2f}")
        cdbg3.metric("üíµ ‡∏£‡∏ß‡∏°‡∏Å‡∏≥‡πÑ‡∏£‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πâ‡∏ô (‡∏ö‡∏≤‡∏ó)", f"{float(sales['Gross profit'].sum()):,.2f}")

        # ====== Build merged for Inventory & Reorder (same as your original) ======
        # Avg cost per unit from sales for fallback
        qty_for_cost = sales["Quantity"].replace(0, np.nan)
        sales["Avg_cost_per_unit_from_sales"] = (sales["Cost of goods"] / qty_for_cost).fillna(0)

        grouped_sales = (
            sales.groupby("SKU", as_index=False)
            .agg(
                Quantity=("Quantity", "sum"),
                Net_sales=("Net sales", "sum"),
                Avg_cost_from_sales=("Avg_cost_per_unit_from_sales", "mean")
            )
        )

        # Keep latest item name (optional)
        if "Item" in sales.columns:
            name_map = (
                sales.sort_values("Date")
                     .drop_duplicates("SKU", keep="last")[["SKU", "Item"]]
                     .rename(columns={"Item": "Name"})
            )
            grouped_sales = grouped_sales.merge(name_map, on="SKU", how="left")

        # Merge with Inventory
        merged = stock.merge(grouped_sales, on="SKU", how="left")
        for col, default in [("Quantity", 0.0), ("Net_sales", 0.0), ("Avg_cost_from_sales", 0.0)]:
            if col not in merged.columns:
                merged[col] = default
            merged[col] = pd.to_numeric(merged[col], errors="coerce").fillna(0.0)

        # fill cost from sales if stock cost missing
        mask_cost_fill = (merged["‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢/‡∏ä‡∏¥‡πâ‡∏ô"].isna()) | (merged["‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢/‡∏ä‡∏¥‡πâ‡∏ô"] == 0)
        merged.loc[mask_cost_fill, "‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢/‡∏ä‡∏¥‡πâ‡∏ô"] = merged["Avg_cost_from_sales"]

        # per-day metrics
        merged["total_profit"]       = merged["Net_sales"] - (merged["Quantity"] * merged["‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢/‡∏ä‡∏¥‡πâ‡∏ô"])
        merged["avg_profit_per_day"] = merged["total_profit"] / max(days_of_sales, 1)
        merged["avg_sales_per_day"]  = merged["Quantity"] / max(days_of_sales, 1)

        # unit profit
        avg_price_per_unit = merged["Net_sales"] / merged["Quantity"].replace(0, np.nan)
        merged["‡∏Å‡∏≥‡πÑ‡∏£‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢/‡∏ä‡∏¥‡πâ‡∏ô"] = (avg_price_per_unit - merged["‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢/‡∏ä‡∏¥‡πâ‡∏ô"]).fillna(0).round(2)

        # coverage & status & RU
        merged["Stock Coverage (Day)"] = merged.apply(
            lambda r: (r["‡∏Ñ‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠"] / r["avg_sales_per_day"]) if r["avg_sales_per_day"] > 0 else np.nan,
            axis=1
        )
        merged["Dead Stock"] = np.where(merged["Quantity"] == 0, "‚ö†Ô∏è ‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏´‡∏ß", "")

        def _status(row):
            if row["‡∏Ñ‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠"] < 0:
                return "Stock ‡∏ï‡∏¥‡∏î‡∏•‡∏ö", row["avg_profit_per_day"]
            if row["‡∏Ñ‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠"] == 0 and row["Quantity"] > 0:
                return "‡∏´‡∏°‡∏î!!!", row["avg_profit_per_day"]
            if row["‡∏Ñ‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠"] == 0 and row["Quantity"] == 0:
                return "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢ Stock = 0", 0
            if row["‡∏Ñ‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠"] > 0 and row["Quantity"] == 0:
                return "‡∏Ç‡∏≤‡∏¢‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏¢ T_T", 0
            cov = row["Stock Coverage (Day)"]
            score = row["avg_profit_per_day"] / cov if pd.notna(cov) and cov > 0 else 0
            return f"{cov:.1f} ‡∏ß‡∏±‡∏ô", score

        merged[["‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞", "RU Score"]] = merged.apply(_status, axis=1, result_type="expand")
        merged = merged[merged["‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞"] != "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢ Stock = 0"].copy()

        # reorder qty
        merged["‡∏Ñ‡∏ß‡∏£‡∏™‡∏±‡πà‡∏á‡∏ã‡∏∑‡πâ‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏° (‡∏ä‡∏¥‡πâ‡∏ô)"] = (
            merged["avg_sales_per_day"] * stock_days - merged["‡∏Ñ‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠"]
        ).apply(lambda x: max(0, int(np.ceil(x))))

        # Opp. Loss
        merged["‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡∏≠‡∏á‡∏Ç‡∏≤‡∏¢"] = merged["Stock Coverage (Day)"].apply(
            lambda x: max(0, int(np.ceil(reorder_days - x))) if pd.notna(x) else reorder_days
        )
        merged["Opp. Loss (Baht)"] = (merged["avg_profit_per_day"] * merged["‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡∏≠‡∏á‡∏Ç‡∏≤‡∏¢"]).round(2)

        # attach Category
        master = try_load_master()
        if master is not None and {"SKU", "Category"}.issubset(master.columns):
            merged = merged.merge(master[["SKU", "Category"]], on="SKU", how="left")
        if "Category" not in merged.columns or merged["Category"].isna().all():
            if "Category" in sales.columns:
                cat_map = sales[["SKU", "Category"]].dropna().drop_duplicates("SKU")
                merged = merged.merge(cat_map, on="SKU", how="left")
            else:
                merged["Category"] = np.nan
        merged["Category_disp"] = merged["Category"].fillna("Uncategorized").astype(str)

        # item name fill
        if "Name" not in merged.columns or merged["Name"].isna().all():
            src_name = None
            for c in ["Item", "Name", "Item name"]:
                if c in sales.columns:
                    src_name = c
                    break
            if src_name:
                imap = (sales[["SKU", src_name]].rename(columns={src_name: "Name"})
                        .dropna(subset=["Name"]).drop_duplicates("SKU", keep="last"))
                merged = merged.merge(imap, on="SKU", how="left", suffixes=("", "_from_sales"))
                if "Name_from_sales" in merged.columns:
                    merged["Name"] = merged["Name"].fillna(merged["Name_from_sales"])
                    merged = merged.drop(columns=["Name_from_sales"])
        merged["Name"] = merged["Name"].fillna(merged["SKU"].astype(str))

        # =============== TABS: Inventory & Reorder | Sales Analysis ===============
        tab_inv, tab_sales, tab_drop = st.tabs([
            "üì¶ Inventory & Reorder",
            "üìä Sales Analysis",
            "üìâ ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏ï‡∏Å"
        ])


        # -------------------- TAB 1: Inventory & Reorder (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏° + bubble) --------------------
        with tab_inv:
            st.subheader("üìÇ ‡∏ü‡∏¥‡∏•‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÅ‡∏•‡∏∞‡∏™‡∏£‡∏∏‡∏õ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏° (Inventory)")
            cats = merged["Category_disp"]
            all_cats = sorted(cats.unique())
            selected = st.multiselect("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Category", options=all_cats, default=all_cats, key="inv_cats")
            filtered = merged[cats.isin(selected)].copy()

            if not filtered.empty:
                summary = (
                    filtered.groupby(filtered["Category_disp"])
                    .agg(
                        Total_RU_Score=("RU Score", "sum"),
                        Total_Opp_Loss_Baht=("Opp. Loss (Baht)", "sum"),
                        Total_Qty=("Quantity", "sum")
                    )
                    .reset_index()
                )

                c1, c2, c3 = st.columns(3)
                c1.metric("RU Score ‡∏£‡∏ß‡∏°", f"{summary['Total_RU_Score'].sum():,.2f}")
                c2.metric("‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡∏¢‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡∏£‡∏ß‡∏° (‡∏ö‡∏≤‡∏ó)", f"{summary['Total_Opp_Loss_Baht'].sum():,.2f}")
                c3.metric("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡∏≤‡∏¢‡∏£‡∏ß‡∏° (‡∏ä‡∏¥‡πâ‡∏ô)", f"{summary['Total_Qty'].sum():,.0f}")

                st.dataframe(
                    fmt_commas(
                        summary,
                        int_cols=["Total_Qty"],
                        float_cols=["Total_RU_Score", "Total_Opp_Loss_Baht"],
                    ),
                    use_container_width=True,
                )


                # Bubble chart
                st.markdown("#### üîµ Bubble: Net sales vs Quantity (size = ‡∏Å‡∏≥‡πÑ‡∏£‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢/‡∏ä‡∏¥‡πâ‡∏ô)")
                tmp = filtered.copy()
                for c in ["Net_sales", "Quantity", "‡∏Å‡∏≥‡πÑ‡∏£‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢/‡∏ä‡∏¥‡πâ‡∏ô"]:
                    tmp[c] = pd.to_numeric(tmp[c], errors="coerce")
                plot_df = tmp[(tmp["Net_sales"] > 0) & (tmp["Quantity"] > 0)]
                if plot_df.empty:
                    st.info("‚ÑπÔ∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö bubble chart")
                else:
                    top_n = plot_df.nlargest(50, "Net_sales").copy()
                    top_n["SKU_Label"] = np.where(
                        top_n["Name"].astype(str).str.strip().ne(""),
                        top_n["Name"].astype(str),
                        top_n["SKU"].astype(str)
                    )
                    chart = (
                        alt.Chart(top_n)
                        .mark_circle(opacity=0.7)
                        .encode(
                            x=alt.X("Net_sales:Q", title="Net sales (Baht)"),
                            y=alt.Y("Quantity:Q",  title="Quantity (units)"),
                            size=alt.Size("‡∏Å‡∏≥‡πÑ‡∏£‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢/‡∏ä‡∏¥‡πâ‡∏ô:Q", title="‡∏Å‡∏≥‡πÑ‡∏£‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢/‡∏ä‡∏¥‡πâ‡∏ô", scale=alt.Scale(zero=False, range=[50, 1200])),
                            color=alt.Color("Category_disp:N", title="Category"),
                            tooltip=[
                                alt.Tooltip("SKU:N",           title="SKU"),
                                alt.Tooltip("SKU_Label:N",     title="Item"),
                                alt.Tooltip("Category_disp:N", title="Category"),
                                alt.Tooltip("Net_sales:Q",     title="Net sales", format=","),
                                alt.Tooltip("Quantity:Q",      title="Quantity",  format=","),
                                alt.Tooltip("‡∏Å‡∏≥‡πÑ‡∏£‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢/‡∏ä‡∏¥‡πâ‡∏ô:Q", title="‡∏Å‡∏≥‡πÑ‡∏£‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢/‡∏ä‡∏¥‡πâ‡∏ô", format=",.2f"),
                            ],
                        )
                        .properties(height=420)
                        .interactive()
                    )
                    st.altair_chart(chart, use_container_width=True)

                # Export & detail table
                st.subheader("üì• Export / üìã ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î")
                st.download_button(
                    "Download Full Report (CSV)",
                    filtered.to_csv(index=False).encode("utf-8"),
                    file_name="smart_reorder_report.csv",
                    mime="text/csv",
                    use_container_width=True
                )
                show_cols = [
                    "SKU", "Name", "Category", "‡∏Ñ‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠", "‡∏Ñ‡∏ß‡∏£‡∏™‡∏±‡πà‡∏á‡∏ã‡∏∑‡πâ‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏° (‡∏ä‡∏¥‡πâ‡∏ô)", "‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞", "RU Score",
                    "Opp. Loss (Baht)", "Dead Stock", "Quantity", "Net_sales", "‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢/‡∏ä‡∏¥‡πâ‡∏ô", "‡∏Å‡∏≥‡πÑ‡∏£‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢/‡∏ä‡∏¥‡πâ‡∏ô"
                ]
                show_cols = [c for c in show_cols if c in filtered.columns]
                st.dataframe(
                    fmt_commas(
                        filtered[show_cols],
                        int_cols=["Quantity", "‡∏Ñ‡∏ß‡∏£‡∏™‡∏±‡πà‡∏á‡∏ã‡∏∑‡πâ‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏° (‡∏ä‡∏¥‡πâ‡∏ô)"],
                        float_cols=["Net_sales", "Opp. Loss (Baht)", "‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢/‡∏ä‡∏¥‡πâ‡∏ô", "‡∏Å‡∏≥‡πÑ‡∏£‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢/‡∏ä‡∏¥‡πâ‡∏ô", "RU Score"],
                    ),
                    use_container_width=True,
                )

            else:
                st.info("‚ÑπÔ∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô Category ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å")

        # -------------------- TAB 2: Sales Analysis (‡πÉ‡∏´‡∏°‡πà) --------------------
        with tab_sales:
            st.subheader("üß≠ ‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡∏≤‡∏¢")
            cA, cB, cC = st.columns([1,1,1])
            with cA:
                timegrain = st.selectbox("Time grain", ["Daily", "Weekly", "Monthly"], index=1)
            with cB:
                cat_options = sorted(sales["Category_disp"].unique())
                sel_cats = st.multiselect("Category", options=cat_options, default=cat_options)
            with cC:
                show_top_n = st.number_input("Top-N (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Top/Bottom)", min_value=5, max_value=50, value=10, step=1)

            sales_f = sales[sales["Category_disp"].isin(sel_cats)].copy()
            if sales_f.empty:
                st.info("‚ÑπÔ∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á")
            else:
                # ===== 1) Time Series: Net sales & Gross profit =====
                st.markdown("### 1) ‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏ï‡∏≤‡∏°‡πÄ‡∏ß‡∏•‡∏≤ (Time Series)")
                ts = make_timegrain(sales_f, timegrain)
                ts_agg = (
                    ts.groupby("Timegrain", as_index=False)
                      .agg(Net_sales=("Net sales","sum"),
                           Gross_profit=("Gross profit","sum"))
                )

                line_net = alt.Chart(ts_agg).mark_line(point=True).encode(
                    x=alt.X("Timegrain:T", title=f"{timegrain}"),
                    y=alt.Y("Net_sales:Q", title="Net sales"),
                    tooltip=[alt.Tooltip("Timegrain:T", title="Period"), alt.Tooltip("Net_sales:Q", format=",")]
                )
                line_gp = alt.Chart(ts_agg).mark_line(point=True).encode(
                    x="Timegrain:T",
                    y=alt.Y("Gross_profit:Q", title="Gross profit"),
                    tooltip=[alt.Tooltip("Timegrain:T"), alt.Tooltip("Gross_profit:Q", format=",")],
                    color=alt.value("#2ca02c")  # ‡∏™‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏á (‡∏õ‡∏•‡πà‡∏≠‡∏¢‡πÑ‡∏ß‡πâ‡∏Å‡πá‡πÑ‡∏î‡πâ ‡∏ñ‡πâ‡∏≤‡∏≠‡∏¢‡∏≤‡∏Å‡∏™‡∏µ default ‡∏•‡∏ö‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ô‡∏µ‡πâ)
                )
                st.altair_chart((line_net + line_gp).resolve_scale(y='independent').properties(height=360), use_container_width=True)

                # ‚úÖ ‡∏ï‡∏≤‡∏£‡∏≤‡∏á MoM ‡∏ï‡πà‡∏≠ Category
                st.markdown("#### üìä ‡∏ï‡∏≤‡∏£‡∏≤‡∏á Net Sales (MoM) ‡∏ï‡πà‡∏≠ Category ‚Äî Value")
                mom_sales = build_mom_table(sales_f, "Category_disp", "Net sales")
                mom_sales_val = mom_sales.pivot(index="Date", columns="Category_disp", values="Value").round(2)
                st.dataframe(fmt_commas(mom_sales_val, float_cols=list(mom_sales_val.columns)), use_container_width=True)

                st.markdown("#### üìä ‡∏ï‡∏≤‡∏£‡∏≤‡∏á Net Sales (MoM) ‡∏ï‡πà‡∏≠ Category ‚Äî Change %")
                mom_sales_chg = mom_sales.pivot(index="Date", columns="Category_disp", values="Change_%").round(2)
                st.dataframe(style_diverging_percent(mom_sales_chg), use_container_width=True)

                st.markdown("#### üìä ‡∏ï‡∏≤‡∏£‡∏≤‡∏á Gross Profit (MoM) ‡∏ï‡πà‡∏≠ Category ‚Äî Value")
                mom_profit = build_mom_table(sales_f, "Category_disp", "Gross profit")
                mom_profit_val = mom_profit.pivot(index="Date", columns="Category_disp", values="Value").round(2)
                st.dataframe(fmt_commas(mom_profit_val, float_cols=list(mom_profit_val.columns)), use_container_width=True)

                st.markdown("#### üìä ‡∏ï‡∏≤‡∏£‡∏≤‡∏á Gross Profit (MoM) ‡∏ï‡πà‡∏≠ Category ‚Äî Change %")
                mom_profit_chg = mom_profit.pivot(index="Date", columns="Category_disp", values="Change_%").round(2)
                st.dataframe(style_diverging_percent(mom_profit_chg), use_container_width=True)


                # ===== NEW: Line chart by Cate_and_band =====
                st.markdown("### üìà ‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏£‡∏≤‡∏¢ Category+Brand (Cate_and_band) ‡∏ï‡∏≤‡∏°‡πÄ‡∏ß‡∏•‡∏≤")

                if "Cate_and_band" not in sales_f.columns:
                    st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Cate_and_band ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡πà‡∏≠‡∏ô")
                else:
                    ts_cb = make_timegrain(sales_f, timegrain)

                    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
                    ts_cb_agg = (
                        ts_cb.groupby(["Timegrain", "Cate_and_band"], as_index=False)
                            .agg(
                                Net_sales=("Net sales", "sum"),
                                Gross_profit=("Gross profit", "sum")
                            )
                    )

                    # üîπ ‡πÅ‡∏¢‡∏Å Category ‡πÉ‡∏´‡∏ç‡πà (‡∏ï‡∏±‡∏î‡∏à‡∏≤‡∏Å Cate_and_band ‡∏Å‡πà‡∏≠‡∏ô [ ... ])
                    ts_cb_agg["Category"] = ts_cb_agg["Cate_and_band"].str.split("[").str[0].str.strip()

                    # üîπ Filter Category (checkbox list)
                    categories = sorted(ts_cb_agg["Category"].unique())
                    selected_categories = st.multiselect(
                        "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Category ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£",
                        options=categories,
                        default=categories[:1]
                    )

                    ts_cb_cat = ts_cb_agg[ts_cb_agg["Category"].isin(selected_categories)]

                    # üîπ Filter Brand (checkbox list)
                    brand_options = sorted(ts_cb_cat["Cate_and_band"].unique())
                    selected_cate_band = st.multiselect(
                        "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Brand (‡∏†‡∏≤‡∏¢‡πÉ‡∏ï‡πâ Category ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å)",
                        options=brand_options,
                        default=brand_options[:5]
                    )

                    ts_cb_cat = ts_cb_cat[ts_cb_cat["Cate_and_band"].isin(selected_cate_band)]

                    # üîπ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Metric (Net Sales / Gross Profit)
                    metric = st.radio(
                        "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Metric ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á",
                        ["Net sales", "Gross profit"],
                        horizontal=True
                    )

                    if ts_cb_cat.empty:
                        st.info("‚ÑπÔ∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å")
                    else:
                        # Chart ‡∏´‡∏•‡∏±‡∏Å
                        main_chart = (
                            alt.Chart(ts_cb_cat)
                            .mark_line(point=True)
                            .encode(
                                x=alt.X("Timegrain:T", title=f"{timegrain}"),
                                y=alt.Y(f"{'Net_sales' if metric=='Net sales' else 'Gross_profit'}:Q",
                                        title=f"{metric} (Baht)"),
                                color=alt.Color("Cate_and_band:N", title="Category+Brand"),
                                tooltip=[
                                    alt.Tooltip("Timegrain:T", title="Period"),
                                    alt.Tooltip("Cate_and_band:N", title="Cate_and_band"),
                                    alt.Tooltip("Net_sales:Q", title="Net sales", format=","),
                                    alt.Tooltip("Gross_profit:Q", title="Gross profit", format=",")
                                ]
                            )
                        )

                        # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Gross Profit ‚Üí ‡πÄ‡∏û‡∏¥‡πà‡∏° Net Sales ‡πÅ‡∏ö‡∏ö‡∏™‡∏µ‡∏≠‡πà‡∏≠‡∏ô
                        if metric == "Gross profit":
                            shadow_chart = (
                                alt.Chart(ts_cb_cat)
                                .mark_line(point=False, strokeDash=[2,2], opacity=0.3)  # ‚úÖ ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏™‡πâ‡∏ô‡∏≠‡πà‡∏≠‡∏ô
                                .encode(
                                    x="Timegrain:T",
                                    y="Net_sales:Q",
                                    color=alt.Color("Cate_and_band:N", legend=None)  # ‡πÉ‡∏ä‡πâ‡∏™‡∏µ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô ‡πÅ‡∏ï‡πà‡πÄ‡∏ö‡∏•‡∏≠
                                )
                            )
                            chart_cb = main_chart + shadow_chart
                        else:
                            chart_cb = main_chart

                        chart_cb = chart_cb.properties(height=400).interactive()
                        st.altair_chart(chart_cb, use_container_width=True)

                # ‚úÖ ‡∏ï‡∏≤‡∏£‡∏≤‡∏á MoM ‡∏ï‡πà‡∏≠ Cate_and_band
                st.markdown("#### üìä ‡∏ï‡∏≤‡∏£‡∏≤‡∏á Net Sales (MoM) ‡∏ï‡πà‡∏≠ Cate_and_band ‚Äî Value")
                mom_sales_cb = build_mom_table(sales_f, "Cate_and_band", "Net sales")
                mom_sales_cb_val = mom_sales_cb.pivot(index="Date", columns="Cate_and_band", values="Value").round(2)
                st.dataframe(fmt_commas(mom_sales_cb_val, float_cols=list(mom_sales_cb_val.columns)), use_container_width=True)

                st.markdown("#### üìä ‡∏ï‡∏≤‡∏£‡∏≤‡∏á Net Sales (MoM) ‡∏ï‡πà‡∏≠ Cate_and_band ‚Äî Change %")
                mom_sales_cb_chg = mom_sales_cb.pivot(index="Date", columns="Cate_and_band", values="Change_%").round(2)
                st.dataframe(style_diverging_percent(mom_sales_cb_chg), use_container_width=True)

                st.markdown("#### üìä ‡∏ï‡∏≤‡∏£‡∏≤‡∏á Gross Profit (MoM) ‡∏ï‡πà‡∏≠ Cate_and_band ‚Äî Value")
                mom_profit_cb = build_mom_table(sales_f, "Cate_and_band", "Gross profit")
                mom_profit_cb_val = mom_profit_cb.pivot(index="Date", columns="Cate_and_band", values="Value").round(2)
                st.dataframe(fmt_commas(mom_profit_cb_val, float_cols=list(mom_profit_cb_val.columns)), use_container_width=True)

                st.markdown("#### üìä ‡∏ï‡∏≤‡∏£‡∏≤‡∏á Gross Profit (MoM) ‡∏ï‡πà‡∏≠ Cate_and_band ‚Äî Change %")
                mom_profit_cb_chg = mom_profit_cb.pivot(index="Date", columns="Cate_and_band", values="Change_%").round(2)
                st.dataframe(style_diverging_percent(mom_profit_cb_chg), use_container_width=True)



                # ===== 2) Top/Bottom Products & Categories =====
                st.markdown("### 2) Top/Bottom Products & Categories")
                sku_agg = (
                    sales_f.groupby(["SKU","Category_disp"], as_index=False)
                    .agg(Net_sales=("Net sales","sum"),
                         Gross_profit=("Gross profit","sum"),
                         Quantity=("Quantity","sum"))
                )
                # item label (‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î)
                if "Item" in sales_f.columns:
                    latest_name = (sales_f.sort_values("Date")
                                   .drop_duplicates("SKU", keep="last")[["SKU","Item"]]
                                   .rename(columns={"Item":"Item_name"}))
                    sku_agg = sku_agg.merge(latest_name, on="SKU", how="left")
                sku_agg["Label"] = sku_agg["Item_name"].fillna(sku_agg["SKU"].astype(str))

                c1, c2 = st.columns(2)
                with c1:
                    st.write(f"üèÜ Top {show_top_n} SKUs by **Net sales**")
                    top_sales = sku_agg.nlargest(show_top_n, "Net_sales")[["Label","Category_disp","Net_sales","Quantity"]]
                    st.dataframe(
                        fmt_commas(top_sales, int_cols=["Quantity"], float_cols=["Net_sales"]),
                        use_container_width=True,
                    )
                with c2:
                    st.write(f"üíµ Top {show_top_n} SKUs by **Gross profit**")
                    top_profit = sku_agg.nlargest(show_top_n, "Gross_profit")[["Label","Category_disp","Gross_profit","Quantity"]]
                    st.dataframe(
                        fmt_commas(top_profit, int_cols=["Quantity"], float_cols=["Gross_profit"]),
                        use_container_width=True,
                    )


                c3, c4 = st.columns(2)
                with c3:
                    st.write(f"üê¢ Slow Movers (Bottom {show_top_n} by Quantity)")
                    slow = sku_agg.nsmallest(show_top_n, "Quantity")[["Label","Category_disp","Quantity","Net_sales"]]
                    st.dataframe(
                        fmt_commas(slow, int_cols=["Quantity"], float_cols=["Net_sales"]),
                        use_container_width=True,
                    )

                with c4:
                    st.write("üì¶ ‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏ï‡∏≤‡∏° Category")
                    cat_agg = (sales_f.groupby("Category_disp", as_index=False)
                               .agg(Net_sales=("Net sales","sum"),
                                    Gross_profit=("Gross profit","sum"),
                                    Quantity=("Quantity","sum")))
                    st.dataframe(
                        fmt_commas(cat_agg, int_cols=["Quantity"], float_cols=["Net_sales", "Gross_profit"]),
                        use_container_width=True,
                    )


                # Pareto 80/20
                st.markdown("#### üç∞ Pareto Analysis (80/20)")
                pareto = sku_agg.sort_values("Net_sales", ascending=False).reset_index(drop=True)
                pareto["cum_sales"] = pareto["Net_sales"].cumsum()
                total_sales = pareto["Net_sales"].sum()
                pareto["cum_share"] = np.where(total_sales>0, pareto["cum_sales"]/total_sales, 0.0)
                pareto["sku_rank"]  = np.arange(1, len(pareto)+1)
                pareto["sku_share"] = pareto["sku_rank"] / max(len(pareto),1)
                top_20pct_n = max(int(np.ceil(0.2*len(pareto))), 1)
                top_20_share = pareto.loc[:top_20pct_n-1, "Net_sales"].sum() / total_sales if total_sales>0 else 0

                cP1, cP2 = st.columns([2,1])
                with cP2:
                    st.metric("‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏à‡∏≤‡∏Å Top 20% SKU", f"{top_20_share*100:,.1f}%")
                    st.caption("‡∏î‡∏π‡∏ß‡πà‡∏≤‡∏Å‡∏é 80/20 ‡∏ñ‡∏∑‡∏≠‡∏à‡∏£‡∏¥‡∏á‡πÑ‡∏´‡∏°‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å")
                with cP1:
                    base = alt.Chart(pareto).encode(x=alt.X("sku_share:Q", title="‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏à‡∏≥‡∏ô‡∏ß‡∏ô SKU ‡∏™‡∏∞‡∏™‡∏°"),
                                                    y=alt.Y("cum_share:Q", title="‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏™‡∏∞‡∏™‡∏°"))
                    line = base.mark_line()
                    points = base.mark_point()
                    rule80 = alt.Chart(pd.DataFrame({"y":[0.8]})).mark_rule(strokeDash=[4,4]).encode(y="y:Q")
                    rule20 = alt.Chart(pd.DataFrame({"x":[0.2]})).mark_rule(strokeDash=[4,4]).encode(x="x:Q")
                    st.altair_chart(line + points + rule80 + rule20, use_container_width=True)

                # ===== 3) Margin Analysis =====
                st.markdown("### 3) ‡∏Å‡∏≥‡πÑ‡∏£‡πÅ‡∏•‡∏∞ Margin Analysis")
                sku_agg["Margin_pct"] = np.where(sku_agg["Net_sales"]>0,
                                                 sku_agg["Gross_profit"]/sku_agg["Net_sales"],
                                                 0.0)
                scat = (alt.Chart(sku_agg)
                        .mark_circle(opacity=0.7)
                        .encode(
                            x=alt.X("Net_sales:Q", title="Net sales"),
                            y=alt.Y("Margin_pct:Q", title="Margin %", axis=alt.Axis(format="%")),
                            size=alt.Size("Quantity:Q", title="Quantity"),
                            color=alt.Color("Category_disp:N", title="Category"),
                            tooltip=["Label:N","Category_disp:N",
                                     alt.Tooltip("Net_sales:Q", format=","),
                                     alt.Tooltip("Gross_profit:Q", format=","),
                                     alt.Tooltip("Margin_pct:Q", format=".1%"),
                                     alt.Tooltip("Quantity:Q", format=",")]
                        ).properties(height=380)
                        .interactive())
                st.altair_chart(scat, use_container_width=True)

                # Contribution Margin (‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡πÉ‡∏î‡∏î‡∏±‡∏ô‡∏Å‡∏≥‡πÑ‡∏£)
                contrib = sku_agg.sort_values("Gross_profit", ascending=False).head(show_top_n)
                st.markdown(f"#### üî• Contribution Margin ‚Äî Top {show_top_n} by Gross Profit")
                st.dataframe(
                    fmt_commas(
                        contrib[["Label","Category_disp","Gross_profit","Net_sales","Quantity"]],
                        int_cols=["Quantity"],
                        float_cols=["Gross_profit","Net_sales"],
                    ),
                    use_container_width=True,
                )


                # ===== 4) Customer Behavior =====
                st.markdown("### 4) Customer Behavior")
                cust_ready = {"Customer name","Customer contacts"}.issubset(sales_f.columns)
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á customer_id ‡πÅ‡∏°‡πâ‡∏ö‡∏≤‡∏á‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô null
                if "Customer name" in sales_f.columns or "Customer contacts" in sales_f.columns:
                    sales_f["Customer name"]    = sales_f.get("Customer name", "").astype(str)
                    sales_f["Customer contacts"] = sales_f.get("Customer contacts", "").astype(str)
                    sales_f["customer_id"] = (sales_f["Customer name"].str.strip() + " | " +
                                              sales_f["Customer contacts"].str.strip()).str.strip(" |")
                else:
                    sales_f["customer_id"] = np.nan

                # Repeat vs New
                if sales_f["customer_id"].notna().any():
                    first_date = (sales_f.sort_values("Date")
                                  .groupby("customer_id", as_index=False)["Date"].min()
                                  .rename(columns={"Date":"first_buy"}))
                    joined = sales_f.merge(first_date, on="customer_id", how="left")
                    joined["is_new"] = joined["Date"].dt.date == joined["first_buy"].dt.date
                    cust_counts = joined.groupby("customer_id").agg(
                        first_buy=("first_buy","min"),
                        orders=("customer_id","count"),
                        total_spent=("Net sales","sum")
                    ).reset_index()
                    cust_counts["type"] = np.where(cust_counts["orders"]>1, "Repeat", "New")
                    total_cust = cust_counts["customer_id"].nunique()
                    new_pct    = (cust_counts["type"].eq("New").mean()*100) if total_cust>0 else 0
                    rep_pct    = 100 - new_pct
                    cR1, cR2, cR3 = st.columns(3)
                    cR1.metric("‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏£‡∏ß‡∏° (unique)", f"{total_cust:,}")
                    cR2.metric("New (%)", f"{new_pct:,.1f}%")
                    cR3.metric("Repeat (%)", f"{rep_pct:,.1f}%")
                else:
                    st.info("‚ÑπÔ∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤ (Customer name/contacts) ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Repeat vs New")

                # Average Basket Size
                # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ Receipt number ‡πÉ‡∏ä‡πâ‡∏≠‡∏±‡∏ô‡∏ô‡∏±‡πâ‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏¥‡∏•; ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡πá group ‡πÇ‡∏î‡∏¢ (Date, customer_id) ‡πÄ‡∏õ‡πá‡∏ô proxy
                if "Receipt number" in sales_f.columns:
                    orders = (sales_f.groupby("Receipt number", as_index=False)
                                      .agg(order_value=("Net sales","sum")))
                elif sales_f["customer_id"].notna().any():
                    orders = (sales_f.groupby(["customer_id", sales_f["Date"].dt.date], as_index=False)
                                      .agg(order_value=("Net sales","sum")))
                else:
                    orders = (sales_f.groupby(sales_f["Date"].dt.date, as_index=False)
                                      .agg(order_value=("Net sales","sum")))
                avg_basket = orders["order_value"].mean() if not orders.empty else 0.0
                st.metric("üõí Average Basket Size (‡∏ö‡∏≤‡∏ó/‡∏ö‡∏¥‡∏•)", f"{avg_basket:,.2f}")

                # Interpurchase Time (IPT)
                if sales_f["customer_id"].notna().any():
                    ipt_list = []
                    for cid, g in sales_f.groupby("customer_id"):
                        ds = g["Date"].sort_values().drop_duplicates().to_list()
                        if len(ds) >= 2:
                            diffs = np.diff(pd.to_datetime(ds)).astype("timedelta64[D]").astype(int)
                            if len(diffs)>0:
                                ipt_list.extend(diffs)
                    if len(ipt_list) > 0:
                        ipt_ser = pd.Series(ipt_list)
                        st.write(f"üìÖ Interpurchase Time (days) ‚Äî mean: **{ipt_ser.mean():.1f}** | median: **{ipt_ser.median():.0f}**")
                        ipt_df = pd.DataFrame({"IPT_days": ipt_ser})
                        hist = alt.Chart(ipt_df).mark_bar().encode(
                            x=alt.X("IPT_days:Q", bin=alt.Bin(maxbins=30), title="Days between purchases"),
                            y=alt.Y("count():Q", title="Count")
                        ).properties(height=250)
                        st.altair_chart(hist, use_container_width=True)

                        # ===== Customer-level IPT summary & items =====
                        st.markdown("#### üë• Interpurchase Summary by Customer")

                        # ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏Ñ‡∏™‡∏ó‡∏µ‡πà‡∏°‡∏µ customer_id
                        if sales_f["customer_id"].notna().any():
                            # 1) ‡∏Å‡∏≥‡∏´‡∏ô‡∏î label ‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤ (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ Item ‡πÉ‡∏ä‡πâ Item ‡πÑ‡∏°‡πà‡∏á‡∏±‡πâ‡∏ô‡πÉ‡∏ä‡πâ SKU)
                            if "Item" in sales_f.columns:
                                sales_f["item_label"] = sales_f["Item"].astype(str).where(
                                    sales_f["Item"].notna(), sales_f["SKU"].astype(str)
                                )
                            else:
                                sales_f["item_label"] = sales_f["SKU"].astype(str)

                            # 2) ‡∏£‡∏ß‡∏°‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥ IPT ‡∏ï‡πà‡∏≠‡∏´‡∏±‡∏ß‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤
                            def _ipt_stats(g: pd.DataFrame) -> pd.Series:
                                ds = g["Date"].sort_values().drop_duplicates().to_numpy()
                                diffs = np.diff(ds).astype("timedelta64[D]").astype(int) if len(ds) >= 2 else np.array([], dtype=int)
                                return pd.Series({
                                    "orders": len(ds),
                                    "IPT_count": len(diffs),
                                    "IPT_mean": float(np.mean(diffs)) if len(diffs) > 0 else np.nan,
                                    "IPT_median": float(np.median(diffs)) if len(diffs) > 0 else np.nan,
                                    "Quantity": g["Quantity"].sum(),
                                    "Total_spent": g["Net sales"].sum(),
                                    "Last_purchase": g["Date"].max(),
                                })

                            cust_stats = (sales_f.groupby("customer_id").apply(_ipt_stats).reset_index())

                            # 3) Top 10 ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ï‡πà‡∏≠‡∏´‡∏±‡∏ß‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤ (‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤ ‚Äî ‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏≤ ‚Äî % ‡∏Ç‡∏≠‡∏á Total_spent)
                            top_items = (
                                sales_f.groupby(["customer_id", "item_label"], as_index=False)
                                    .agg(spent=("Net sales","sum"))
                            ).merge(
                                cust_stats[["customer_id","Total_spent"]], on="customer_id", how="left"
                            )

                            top_items["pct"] = np.where(
                                top_items["Total_spent"] > 0,
                                100 * top_items["spent"] / top_items["Total_spent"],
                                0
                            )

                            # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å top 10 ‡∏ï‡πà‡∏≠ customer ‡πÅ‡∏•‡∏∞‡∏£‡∏ß‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏•‡∏≤‡∏¢‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î
                            top_items = (
                                top_items.sort_values(["customer_id","spent"], ascending=[True, False])
                                        .groupby("customer_id")
                                        .head(10)
                            )
                            top_items["detail"] = top_items.apply(
                                lambda r: f"{r['item_label']} ‚Äî {r['spent']:,.0f}‡∏ø ({r['pct']:.1f}%)", axis=1
                            )
                            items_fmt = (
                                top_items.groupby("customer_id")["detail"]
                                        .apply(lambda s: "\n".join(s))
                                        .reset_index(name="Top 10 purchases")
                            )

                            # 4) ‡∏£‡∏ß‡∏°‡∏Å‡∏•‡∏±‡∏ö‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö
                            cust_stats = (cust_stats
                                        .merge(items_fmt, on="customer_id", how="left")
                                        .sort_values(["IPT_count","orders","Total_spent"],
                                                    ascending=[False, False, False]))

                            # 5) ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• (‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏î‡∏µ‡∏¢‡∏ß)
                            cols = [
                                "customer_id","orders","IPT_count","IPT_mean","IPT_median",
                                "Quantity","Total_spent","Last_purchase","Top 10 purchases"
                            ]
                            st.dataframe(
                                fmt_commas(
                                    cust_stats[cols],
                                    int_cols=["orders","IPT_count","Quantity"],
                                    float_cols=["IPT_mean","IPT_median","Total_spent"],
                                ),
                                use_container_width=True,
                            )

                            st.caption("‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: IPT_count ‡∏Ñ‡∏∑‡∏≠‡∏à‡∏≥‡∏ô‡∏ß‡∏ô '‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ã‡∏∑‡πâ‡∏≠' ‡∏ï‡πà‡∏≠‡∏´‡∏±‡∏ß‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤ (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤)")

        # ---------------- TAB 3: ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏ï‡∏Å ----------------
        with tab_drop:
            st.subheader("üìâ ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏ï‡∏Å")

            months = sorted(sales["Date"].dt.to_period("M").astype(str).unique())
            if len(months) < 2:
                st.info("‚ÑπÔ∏è ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 2 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô")
            else:
                month_curr = st.selectbox(
                    "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô (Curr)", months, index=len(months)-1, key="drop_curr_only"
                )

                # ‡∏´‡∏≤‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤ (prev)
                month_pos = months.index(month_curr)
                if month_pos == 0:
                    st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö")
                else:
                    month_prev = months[month_pos - 1]

                    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≤‡∏¢‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì MA (exclude current for MA baseline)
                    sales["Month"] = sales["Date"].dt.to_period("M").astype(str)
                    monthly_all = (sales.groupby(["Month", "Cate_and_band"], as_index=False)
                                        .agg(Net_Sales=("Net sales", "sum")))

                    # ‡∏™‡∏£‡πâ‡∏≤‡∏á index ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô (‡πÅ‡∏°‡πâ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ‡∏ï‡∏£‡∏á ‡πÜ ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì MA ‡πÉ‡∏´‡∏°‡πà)
                    month_order = sorted(monthly_all["Month"].unique())
                    month_index = {m: i for i, m in enumerate(month_order)}
                    monthly_all["month_idx"] = monthly_all["Month"].map(month_index)
                    monthly_all = monthly_all.sort_values(["Cate_and_band", "month_idx"])

                    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ 3 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤ (‡πÑ‡∏°‡πà‡∏£‡∏ß‡∏°‡πÄ‡∏î‡∏∑‡∏≠‡∏ô prev) = ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ç‡∏≠‡∏á‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏´‡πà‡∏≤‡∏á 2,3,4 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏Å‡πà‡∏≠‡∏ô curr
                    # ‡πÉ‡∏ä‡πâ shift(2), shift(3), shift(4) ‡∏ï‡πà‡∏≠ Cate_and_band ‡πÅ‡∏•‡πâ‡∏ß‡∏´‡∏≤ mean ‡∏Ç‡πâ‡∏≤‡∏° 3 ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
                    grp = monthly_all.groupby("Cate_and_band")
                    monthly_all["lag2"] = grp["Net_Sales"].shift(2)
                    monthly_all["lag3"] = grp["Net_Sales"].shift(3)
                    monthly_all["lag4"] = grp["Net_Sales"].shift(4)
                    monthly_all["MA_3m_prev"] = monthly_all[["lag2", "lag3", "lag4"]].mean(axis=1, skipna=True)

                    # ‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤‡∏Ç‡∏≠‡∏á‡πÄ‡∏î‡∏∑‡∏≠‡∏ô prev / curr
                    curr_df = monthly_all[monthly_all["Month"] == month_curr][["Cate_and_band", "Net_Sales"]].rename(columns={"Net_Sales": "Net_Sales_curr"})
                    prev_df = monthly_all[monthly_all["Month"] == month_prev][["Cate_and_band", "Net_Sales", "MA_3m_prev"]].rename(columns={"Net_Sales": "Net_Sales_prev"})

                    merged = curr_df.merge(prev_df, on="Cate_and_band", how="left")
                    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Change
                    merged["Change"] = merged["Net_Sales_curr"] - merged["Net_Sales_prev"].fillna(0)
                    merged["Change_%"] = np.where(
                        merged["Net_Sales_prev"] > 0,
                        (merged["Change"] / merged["Net_Sales_prev"]) * 100,
                        np.nan
                    )

                    # MA_3m_prev ‡∏Ñ‡∏∑‡∏≠ baseline (‡∏™‡∏≤‡∏°‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏Å‡πà‡∏≠‡∏ô curr ‡πÑ‡∏°‡πà‡∏£‡∏ß‡∏° curr) ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å prev row (‡∏≠‡∏≤‡∏à NaN)
                    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì MA_Change = Curr - MA_3m_prev
                    merged["MA_Change"] = merged["Net_Sales_curr"] - merged["MA_3m_prev"]
                    merged["MA_Change_%"] = np.where(
                        merged["MA_3m_prev"] > 0,
                        (merged["MA_Change"] / merged["MA_3m_prev"]) * 100,
                        np.nan
                    )

                    # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏ï‡∏Å (Change < 0)
                    top_n_drop = st.slider("‡πÅ‡∏™‡∏î‡∏á Top N ‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏•‡∏î‡∏•‡∏á‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î", min_value=5, max_value=50, value=20, step=5)
                    drops = merged[merged["Change"] < 0].sort_values("Change").head(top_n_drop).reset_index(drop=True)

                    if not drops.empty:
                        absmax = np.nanmax(np.abs(drops["Change_%"])) if drops["Change_%"].notna().any() else None
                        absmax_ma = np.nanmax(np.abs(drops["MA_Change_%"])) if drops["MA_Change_%"].notna().any() else absmax
                        sty = (drops.style
                               .format({
                                   "Net_Sales_prev": "{:,.2f}",
                                   "Net_Sales_curr": "{:,.2f}",
                                   "Change": "{:,.2f}",
                                   "Change_%": "{:+,.2f}%",
                                   "MA_3m_prev": "{:,.2f}",
                                   "MA_Change": "{:,.2f}",
                                   "MA_Change_%": "{:+,.2f}%",
                               })
                               .background_gradient(cmap="RdYlGn", vmin=(-absmax if absmax else None), vmax=(absmax if absmax else None), subset=["Change_%"]) 
                               .background_gradient(cmap="PuOr", vmin=(-absmax_ma if absmax_ma else None), vmax=(absmax_ma if absmax_ma else None), subset=["MA_Change_%"]))
                        st.dataframe(sty, use_container_width=True)
                        st.caption("‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: MA_3m_prev = ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ 3 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤ (‡πÑ‡∏°‡πà‡∏£‡∏ß‡∏°‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô)")

                        # ===== ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏ï‡πà‡∏≠ Cate_and_band (expanders) =====
                        all_lost_collector = []  # ‡∏à‡∏∞‡πÄ‡∏Å‡πá‡∏ö lost ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ Cate_and_band ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡∏∏‡∏õ‡∏ó‡πâ‡∏≤‡∏¢‡∏´‡∏ô‡πâ‡∏≤
                        if "Item" not in sales.columns:
                            st.info("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Item ‡∏à‡∏∂‡∏á‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡πÑ‡∏î‡πâ")
                        else:
                            # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏â‡∏û‡∏≤‡∏∞ 2 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô (prev / curr) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡∏Å‡∏≤‡∏£ filter ‡∏ã‡πâ‡∏≥
                            if "Month" not in sales.columns:
                                sales["Month"] = sales["Date"].dt.to_period("M").astype(str)
                            sales_prev_all = sales[sales["Month"] == month_prev]
                            sales_curr_all = sales[sales["Month"] == month_curr]

                            # ‡∏ß‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ Cate_and_band ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏¢‡∏≠‡∏î‡∏ï‡∏Å
                            for cb in drops["Cate_and_band"].tolist():
                                with st.expander(f"üîΩ {cb} ‚Äî ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°", expanded=False):
                                    sub_prev = sales_prev_all[sales_prev_all["Cate_and_band"] == cb]
                                    sub_curr = sales_curr_all[sales_curr_all["Cate_and_band"] == cb]

                                    # 1) ‡∏ï‡∏≤‡∏£‡∏≤‡∏á Item ‡∏ó‡∏µ‡πà‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏•‡∏î‡∏•‡∏á
                                    prev_items = (sub_prev.groupby("Item", as_index=False)["Net sales"].sum()
                                                            .rename(columns={"Net sales": "Net_Sales_prev"}))
                                    curr_items = (sub_curr.groupby("Item", as_index=False)["Net sales"].sum()
                                                            .rename(columns={"Net sales": "Net_Sales_curr"}))
                                    item_merge = curr_items.merge(prev_items, on="Item", how="outer").fillna(0)
                                    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Change
                                    item_merge["Change"] = item_merge["Net_Sales_curr"] - item_merge["Net_Sales_prev"]
                                    item_merge["Change_%"] = np.where(
                                        item_merge["Net_Sales_prev"] > 0,
                                        (item_merge["Change"] / item_merge["Net_Sales_prev"]) * 100,
                                        np.nan
                                    )
                                    # ‡πÄ‡∏≠‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏µ‡πà‡∏•‡∏î‡∏•‡∏á
                                    items_drop = item_merge[item_merge["Change"] < 0].sort_values("Change")
                                    st.markdown("**üì¶ ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡πÉ‡∏ô Cate_and_band ‡∏ó‡∏µ‡πà‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏•‡∏î‡∏•‡∏á**")
                                    if items_drop.empty:
                                        st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡πÉ‡∏î‡∏°‡∏µ‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏•‡∏î‡∏•‡∏á")
                                    else:
                                        st.dataframe(
                                            fmt_commas(
                                                items_drop[["Item","Net_Sales_prev","Net_Sales_curr","Change"]]
                                                          .assign(**{"Change_%": items_drop["Change_%"].round(2)}),
                                                float_cols=["Net_Sales_prev","Net_Sales_curr","Change"],
                                            ).format({"Change_%": "{:+,.2f}%"}),
                                            use_container_width=True,
                                        )

                                    # 2) ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ (‡∏ã‡∏∑‡πâ‡∏≠ prev ‡πÑ‡∏°‡πà‡∏ã‡∏∑‡πâ‡∏≠ curr)
                                    st.markdown("**üßç‚Äç‚ôÄÔ∏è ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ (‡∏ã‡∏∑‡πâ‡∏≠‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏Å‡πà‡∏≠‡∏ô ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏ã‡∏∑‡πâ‡∏≠‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô)**")
                                    if not {"Customer name","Customer contacts"}.issubset(sales.columns):
                                        st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Customer name ‡πÅ‡∏•‡∏∞/‡∏´‡∏£‡∏∑‡∏≠ Customer contacts ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠")
                                    else:
                                        prev_cust = sub_prev.copy()
                                        curr_cust = sub_curr.copy()
                                        # ‡∏£‡∏ß‡∏°‡∏™‡∏≠‡∏á field ‡πÄ‡∏õ‡πá‡∏ô customer_key
                                        prev_cust["customer_key"] = (
                                            prev_cust["Customer name"].astype(str).str.strip() + " | " +
                                            prev_cust["Customer contacts"].astype(str).str.strip()
                                        ).str.strip(" |")
                                        curr_cust["customer_key"] = (
                                            curr_cust["Customer name"].astype(str).str.strip() + " | " +
                                            curr_cust["Customer contacts"].astype(str).str.strip()
                                        ).str.strip(" |")
                                        prev_cust_agg = (prev_cust.groupby("customer_key", as_index=False)["Net sales"].sum()
                                                                  .rename(columns={"Net sales": "Net_Sales_prev"}))
                                        curr_keys = set(curr_cust["customer_key"].unique())
                                        lost = prev_cust_agg[~prev_cust_agg["customer_key"].isin(curr_keys)].copy()
                                        lost = lost.sort_values("Net_Sales_prev", ascending=False)
                                        if lost.empty:
                                            st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ‡πÉ‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ô‡∏µ‡πâ")
                                        else:
                                            lost["‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ"] = lost["Net_Sales_prev"]
                                            # ‡πÄ‡∏Å‡πá‡∏ö‡∏£‡∏ß‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡∏∏‡∏õ‡∏ó‡πâ‡∏≤‡∏¢‡∏´‡∏ô‡πâ‡∏≤ (‡πÄ‡∏û‡∏¥‡πà‡∏° Cate_and_band ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô)
                                            lost_with_cb = lost.assign(Cate_and_band=cb)
                                            all_lost_collector.append(lost_with_cb)
                                            st.dataframe(
                                                fmt_commas(
                                                    lost[["customer_key","Net_Sales_prev","‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ"]],
                                                    float_cols=["Net_Sales_prev","‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ"],
                                                ),
                                                use_container_width=True,
                                            )
                                            st.write(f"**‡∏£‡∏ß‡∏°‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏≤‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ:** {lost['Net_Sales_prev'].sum():,.2f} ‡∏ö‡∏≤‡∏ó")

                                            # ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤ (Item) ‡∏ó‡∏µ‡πà‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏ô‡∏ã‡∏∑‡πâ‡∏≠‡πÉ‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤
                                            if "Item" in prev_cust.columns:
                                                for _, crow in lost.iterrows():
                                                    ckey = crow["customer_key"]
                                                    c_total = crow["Net_Sales_prev"]
                                                    cust_items_prev = prev_cust[prev_cust["customer_key"] == ckey]
                                                    item_detail = (cust_items_prev.groupby(["Item","Cate_and_band"], as_index=False)["Net sales"].sum()
                                                                                  .rename(columns={"Item":"Item_name","Net sales":"Net_Sales_prev"}))
                                                    item_detail = item_detail[item_detail["Net_Sales_prev"] > 0]
                                                    if item_detail.empty:
                                                        continue
                                                    item_detail["‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ"] = item_detail["Net_Sales_prev"]
                                                    item_detail = item_detail.sort_values("‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ", ascending=False)
                                                    with st.expander(f"üßç‚Äç‚ôÄÔ∏è {ckey} ‚Äì ‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ‡∏£‡∏ß‡∏° {c_total:,.2f} ‡∏ö‡∏≤‡∏ó", expanded=False):
                                                        st.dataframe(
                                                            fmt_commas(
                                                                item_detail[["Item_name","Cate_and_band","Net_Sales_prev","‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ"]],
                                                                float_cols=["Net_Sales_prev","‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ"],
                                                            ),
                                                            use_container_width=True,
                                                        )
                                                        st.caption("‡∏¢‡∏≠‡∏î Net_Sales_prev = ‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏ã‡∏∑‡πâ‡∏≠")

                        # ===== ‡∏™‡∏£‡∏∏‡∏õ‡∏ó‡πâ‡∏≤‡∏¢‡∏´‡∏ô‡πâ‡∏≤ ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ (‡∏£‡∏ß‡∏°‡∏ó‡∏∏‡∏Å Cate_and_band ‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô drops) =====
                        if all_lost_collector:
                            lost_all_df = pd.concat(all_lost_collector, ignore_index=True)
                            st.markdown("---")
                            st.markdown(
                                f"**‡∏™‡∏£‡∏∏‡∏õ‡∏£‡∏ß‡∏°‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î:** {lost_all_df['customer_key'].nunique()} ‡∏£‡∏≤‡∏¢ | ‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ‡∏£‡∏ß‡∏° {lost_all_df['Net_Sales_prev'].sum():,.2f} ‡∏ö‡∏≤‡∏ó"
                            )

                        # ========== SECTION: Customers with decreased spend (still active) ==========
                        st.markdown("### üìâ ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏¢‡∏≠‡∏î‡∏ã‡∏∑‡πâ‡∏≠‡∏•‡∏î‡∏•‡∏á (‡∏¢‡∏±‡∏á‡∏Ñ‡∏á‡∏ã‡∏∑‡πâ‡∏≠ ‡πÅ‡∏ï‡πà‡∏¢‡∏≠‡∏î‡∏•‡∏î‡∏•‡∏á)")
                        if not {"Customer name","Customer contacts"}.issubset(sales.columns):
                            st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Customer name / Customer contacts ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì")
                        else:
                            # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° subset ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô prev / curr ‡∏ó‡∏±‡πà‡∏ß‡∏ó‡∏±‡πâ‡∏á dataset (‡πÑ‡∏°‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÄ‡∏â‡∏û‡∏≤‡∏∞ Cate_and_band ‡∏ó‡∏µ‡πà‡∏ï‡∏Å)
                            if "Month" not in sales.columns:
                                sales["Month"] = sales["Date"].dt.to_period("M").astype(str)
                            sales_prev_all2 = sales[sales["Month"] == month_prev].copy()
                            sales_curr_all2 = sales[sales["Month"] == month_curr].copy()

                            # ‡∏™‡∏£‡πâ‡∏≤‡∏á customer_key
                            for df_tmp in (sales_prev_all2, sales_curr_all2):
                                df_tmp["customer_key"] = (
                                    df_tmp["Customer name"].astype(str).str.strip() + " | " +
                                    df_tmp["Customer contacts"].astype(str).str.strip()
                                ).str.strip(" |")

                            # Aggregate ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤
                            prev_cust_all = (sales_prev_all2.groupby("customer_key", as_index=False)["Net sales"].sum()
                                                             .rename(columns={"Net sales":"Net_Sales_prev"}))
                            curr_cust_all = (sales_curr_all2.groupby("customer_key", as_index=False)["Net sales"].sum()
                                                             .rename(columns={"Net sales":"Net_Sales_curr"}))
                            cust_merge = prev_cust_all.merge(curr_cust_all, on="customer_key", how="inner")  # ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≠‡∏á‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
                            if cust_merge.empty:
                                st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏û‡∏ö‡πÉ‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≠‡∏á‡πÄ‡∏î‡∏∑‡∏≠‡∏ô")
                            else:
                                cust_merge["Change"] = cust_merge["Net_Sales_curr"] - cust_merge["Net_Sales_prev"]
                                cust_merge["Change_%"] = np.where(
                                    cust_merge["Net_Sales_prev"] > 0,
                                    (cust_merge["Change"] / cust_merge["Net_Sales_prev"]) * 100,
                                    np.nan
                                )
                                # ‡∏Ñ‡∏±‡∏î‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏¢‡∏≠‡∏î‡∏•‡∏î‡∏•‡∏á
                                cust_drop = cust_merge[cust_merge["Change"] < 0].copy().sort_values("Change")
                                if cust_drop.empty:
                                    st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏¢‡∏≠‡∏î‡∏ã‡∏∑‡πâ‡∏≠‡∏•‡∏î‡∏•‡∏á")
                                else:
                                    total_cust_drop = cust_drop["customer_key"].nunique()
                                    total_value_drop = cust_drop["Change"].sum()  # ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡∏•‡∏ö
                                    st.markdown(f"**‡∏£‡∏ß‡∏°‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏¢‡∏≠‡∏î‡∏•‡∏î‡∏•‡∏á:** {total_cust_drop} ‡∏£‡∏≤‡∏¢ | ‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏•‡∏î‡∏•‡∏á‡∏£‡∏ß‡∏° {total_value_drop:,.2f} ‡∏ö‡∏≤‡∏ó")

                                    show_cols_cust = ["customer_key","Net_Sales_prev","Net_Sales_curr","Change","Change_%"]
                                    # ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏´‡∏•‡∏±‡∏Å
                                    st.dataframe(
                                        fmt_commas(
                                            cust_drop.assign(**{"Change_%": cust_drop["Change_%"].round(2)})[show_cols_cust],
                                            float_cols=["Net_Sales_prev","Net_Sales_curr","Change"],
                                        ).format({"Change_%": "{:+,.2f}%"}),
                                        use_container_width=True,
                                    )

                                    # ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏≤‡∏•‡∏î‡∏•‡∏á
                                    st.markdown("**‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤ (‡∏Ñ‡∏•‡∏¥‡∏Å‡∏ó‡∏µ‡πà‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ç‡∏¢‡∏≤‡∏¢)**")
                                    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° item aggregates ‡∏Ç‡∏≠‡∏á‡∏™‡∏≠‡∏á‡πÄ‡∏î‡∏∑‡∏≠‡∏ô (‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤ + item + cate_and_band)
                                    prev_items_all = (sales_prev_all2.groupby(["customer_key","Item","Cate_and_band"], as_index=False)["Net sales"].sum()
                                                                        .rename(columns={"Net sales":"Net_Sales_prev"}))
                                    curr_items_all = (sales_curr_all2.groupby(["customer_key","Item","Cate_and_band"], as_index=False)["Net sales"].sum()
                                                                        .rename(columns={"Net sales":"Net_Sales_curr"}))

                                    for _, rowc in cust_drop.iterrows():
                                        ckey = rowc["customer_key"]
                                        c_total_drop = rowc["Change"]  # ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡∏•‡∏ö
                                        # item prev/curr ‡∏Ç‡∏≠‡∏á‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ô‡∏µ‡πâ
                                        cust_prev_items = prev_items_all[prev_items_all["customer_key"] == ckey]
                                        cust_curr_items = curr_items_all[curr_items_all["customer_key"] == ckey]
                                        item_merge = cust_prev_items.merge(
                                            cust_curr_items,
                                            on=["customer_key","Item","Cate_and_band"],
                                            how="left"
                                        )
                                        item_merge["Net_Sales_curr"] = item_merge["Net_Sales_curr"].fillna(0)
                                        item_merge["Change"] = item_merge["Net_Sales_curr"] - item_merge["Net_Sales_prev"]
                                        item_merge["Change_%"] = np.where(
                                            item_merge["Net_Sales_prev"] > 0,
                                            (item_merge["Change"] / item_merge["Net_Sales_prev"]) * 100,
                                            np.nan
                                        )
                                        # ‡πÄ‡∏≠‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞ item ‡∏ó‡∏µ‡πà‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏≤‡∏•‡∏î‡∏•‡∏á
                                        item_drop = item_merge[item_merge["Change"] < 0].copy().sort_values("Change")
                                        if item_drop.empty:
                                            continue
                                        with st.expander(f"üìâ {ckey} ‚Äì ‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏≤‡∏•‡∏î‡∏•‡∏á {c_total_drop:,.2f} ‡∏ö‡∏≤‡∏ó", expanded=False):
                                            st.dataframe(
                                                fmt_commas(
                                                    item_drop.assign(**{"Change_%": item_drop["Change_%"].round(2)})[[
                                                        "Item","Cate_and_band","Net_Sales_prev","Net_Sales_curr","Change","Change_%"
                                                    ]],
                                                    float_cols=["Net_Sales_prev","Net_Sales_curr","Change"],
                                                ).format({"Change_%": "{:+,.2f}%"}),
                                                use_container_width=True,
                                            )
                                    st.caption("‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ô‡∏µ‡πâ‡∏¢‡∏±‡∏á‡∏ã‡∏∑‡πâ‡∏≠‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô ‡πÅ‡∏ï‡πà‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏•‡∏î‡∏•‡∏á‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤")

                    else:
                        st.info("‚ÑπÔ∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ Cate_and_band ‡∏ó‡∏µ‡πà‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏•‡∏î‡∏•‡∏á‡πÉ‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤")

    except Exception as e:
        st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
        st.exception(e)
else:
    st.info("‚¨ÜÔ∏è ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Sales ‡πÅ‡∏•‡∏∞ Inventory ‡πÅ‡∏•‡πâ‡∏ß‡∏Å‡∏î **Run Analysis** ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì")
